{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import foolbox\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistModel, self).__init__()\n",
    "        # mnist의 경우 28*28의 흑백이미지(input channel=1)이다.\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size = 5, padding=2)\n",
    "        # feature map의 크기는 14*14가 된다\n",
    "        # 첫번재 convolution layer에서 나온 output channel이 32이므로 2번째 input도 32\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size = 5, padding=2)\n",
    "        # feature map의 크기는 7*7이 된다\n",
    "        # fc -> fully connected, fc는 모든 weight를 고려해서 만들기 때문에 cnn에서는 locally connected를 이용하여 만든다.\n",
    "        # nn.Linear에서는 conv를 거친 feature map을 1차원으로 전부 바꿔서 input을 한다. 이게 64*7*7\n",
    "        self.fc1 = nn.Linear(64*7*7, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, 64*7*7) # linear에 들어갈 수 있도록 reshape\n",
    "        x = F.relu(self.fc1(x)) # fully connected에 relu 적용\n",
    "        x = F.dropout(x, training=self.training) # 가중치 감소만으로는 overfit을 해결하기가 어려움, 그래서 뉴런의 연결을 임의로 삭제\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advtrain(model, device, train_loader, optimizer, epoch, log_interval, train_loader_origin):\n",
    "    model.train()\n",
    "    avg_loss = 0\n",
    "    # in training loop:\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # gpu나 cpu로 데이터를 옮김\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # gradient descent전에 gradient buffer를 0으로 초기화 하는 역할을 한다\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # negative log-likelihood: nll loss, 딥러닝 모델의 손실함수이다\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step() # Does the update based on the current gradient stored in grad\n",
    "        # 여기서 기존에 저장되어있던 gradient를 기반으로 update 하기 때문에 위의 초기화가 필요함\n",
    "        avg_loss+=F.nll_loss(output, target, reduction='sum').item()\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader_origin.dataset),\n",
    "                100. * batch_idx / len(train_loader_origin), loss.item()))\n",
    "    avg_loss/=len(train_loader_origin.dataset)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, images):\n",
    "    # Accuracy counter\n",
    "    correct = 0\n",
    "    failed_examples = []\n",
    "    correct_examples = []\n",
    "\n",
    "    # test set의 모든 예제를 test한다\n",
    "    for image, label in images:\n",
    "        # cpu나 gpu로 데이터를 전송한다\n",
    "        image, label = image.to(device), label.to(device)\n",
    "\n",
    "        # Re-classify the perturbed image\n",
    "        output = model(image)\n",
    "\n",
    "        # Check for success\n",
    "        final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        if final_pred.item() == label.item():\n",
    "            correct += 1\n",
    "            if (len(correct_examples) < 5):\n",
    "                adv_ex = image.squeeze().detach().cpu().numpy()\n",
    "                correct_examples.append( (label.item(), final_pred.item(), adv_ex) )\n",
    "        else:\n",
    "            if len(failed_examples) < 5:\n",
    "                adv_ex = image.squeeze().detach().cpu().numpy()\n",
    "                failed_examples.append( (label.item(), final_pred.item(), adv_ex) )\n",
    "\n",
    "    # final_acc = correct/idx\n",
    "    final_acc = correct/float(len(images))\n",
    "    print(\"Test Accuracy = {} / {} = {}\".format(correct, len(images), final_acc))\n",
    "\n",
    "    # Return the accuracy and an adversarial example\n",
    "    return final_acc, correct_examples, failed_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size=64\n",
    "test_batch_size=1\n",
    "epochs=50\n",
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "seed = 1\n",
    "log_interval = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if is_cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model = './model/mnist_um.pth'\n",
    "model = MnistModel().to(device).eval()\n",
    "model.load_state_dict(torch.load(pretrained_model, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# momentum: 기울기에서 속도의 개념을 추가, 기울기 업데이트시 폭을 조절한다\n",
    "# lr: learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "# mean=0.5 std=1.0으로 Normalize한다\n",
    "mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_path = './data'\n",
    "train_dataset = MNIST(download_path, transform=mnist_transform, train=True, download=True)\n",
    "test_dataset = MNIST(download_path, transform=mnist_transform, train=False, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=train_batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=test_batch_size,\n",
    "                                          shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepfool_attack(model, loader):\n",
    "    print(\"Attack image!\")\n",
    "    \n",
    "    perturbed_images = []\n",
    "    for image, label in loader:\n",
    "        attack = foolbox.attacks.DeepFoolAttack(model)\n",
    "        image_np = attack(image.numpy(), label.numpy())\n",
    "        perturbed_image = torch.from_numpy(image_np)\n",
    "        perturbed_images.append((perturbed_image, label))\n",
    "        \n",
    "    print(\"Attack done!\")\n",
    "    return perturbed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmodel = foolbox.models.PyTorchModel(model, bounds=(0, 1), num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack image!\n",
      "Attack done!\n"
     ]
    }
   ],
   "source": [
    "perturbed_test = deepfool_attack(fmodel, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack image!\n",
      "Attack done!\n"
     ]
    }
   ],
   "source": [
    "perturbed_train = deepfool_attack(fmodel, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 13.331134\n",
      "Test Accuracy = 1937 / 10000 = 0.1937\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.111191\n",
      "Test Accuracy = 2267 / 10000 = 0.2267\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.100425\n",
      "Test Accuracy = 2334 / 10000 = 0.2334\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.065625\n",
      "Test Accuracy = 2636 / 10000 = 0.2636\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.026779\n",
      "Test Accuracy = 2989 / 10000 = 0.2989\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.012778\n",
      "Test Accuracy = 2796 / 10000 = 0.2796\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.011426\n",
      "Test Accuracy = 2831 / 10000 = 0.2831\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.010224\n",
      "Test Accuracy = 3148 / 10000 = 0.3148\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.022377\n",
      "Test Accuracy = 2920 / 10000 = 0.292\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.006654\n",
      "Test Accuracy = 3035 / 10000 = 0.3035\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.004472\n",
      "Test Accuracy = 2895 / 10000 = 0.2895\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.025095\n",
      "Test Accuracy = 3013 / 10000 = 0.3013\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.008886\n",
      "Test Accuracy = 3178 / 10000 = 0.3178\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.034044\n",
      "Test Accuracy = 3087 / 10000 = 0.3087\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.003365\n",
      "Test Accuracy = 3183 / 10000 = 0.3183\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.002181\n",
      "Test Accuracy = 3149 / 10000 = 0.3149\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.014160\n",
      "Test Accuracy = 3029 / 10000 = 0.3029\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.001996\n",
      "Test Accuracy = 3121 / 10000 = 0.3121\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.001698\n",
      "Test Accuracy = 3161 / 10000 = 0.3161\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.000972\n",
      "Test Accuracy = 2851 / 10000 = 0.2851\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.002622\n",
      "Test Accuracy = 3117 / 10000 = 0.3117\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.001292\n",
      "Test Accuracy = 3163 / 10000 = 0.3163\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.025697\n",
      "Test Accuracy = 2924 / 10000 = 0.2924\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.001502\n",
      "Test Accuracy = 2933 / 10000 = 0.2933\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.001250\n",
      "Test Accuracy = 2985 / 10000 = 0.2985\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.015667\n",
      "Test Accuracy = 3099 / 10000 = 0.3099\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.002306\n",
      "Test Accuracy = 3002 / 10000 = 0.3002\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.001164\n",
      "Test Accuracy = 2986 / 10000 = 0.2986\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.000475\n",
      "Test Accuracy = 3200 / 10000 = 0.32\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.002289\n",
      "Test Accuracy = 2919 / 10000 = 0.2919\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.001073\n",
      "Test Accuracy = 2953 / 10000 = 0.2953\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.000600\n",
      "Test Accuracy = 3053 / 10000 = 0.3053\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.002559\n",
      "Test Accuracy = 2978 / 10000 = 0.2978\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.002149\n",
      "Test Accuracy = 3044 / 10000 = 0.3044\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.000655\n",
      "Test Accuracy = 2917 / 10000 = 0.2917\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.002775\n",
      "Test Accuracy = 3008 / 10000 = 0.3008\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.000671\n",
      "Test Accuracy = 3006 / 10000 = 0.3006\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.003052\n",
      "Test Accuracy = 3071 / 10000 = 0.3071\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.002611\n",
      "Test Accuracy = 3093 / 10000 = 0.3093\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.000306\n",
      "Test Accuracy = 3023 / 10000 = 0.3023\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.001621\n",
      "Test Accuracy = 3054 / 10000 = 0.3054\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.003732\n",
      "Test Accuracy = 3010 / 10000 = 0.301\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.000941\n",
      "Test Accuracy = 2899 / 10000 = 0.2899\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.001686\n",
      "Test Accuracy = 2961 / 10000 = 0.2961\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.000571\n",
      "Test Accuracy = 3004 / 10000 = 0.3004\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.000387\n",
      "Test Accuracy = 2976 / 10000 = 0.2976\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.000046\n",
      "Test Accuracy = 3075 / 10000 = 0.3075\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.001749\n",
      "Test Accuracy = 3089 / 10000 = 0.3089\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.000348\n",
      "Test Accuracy = 2941 / 10000 = 0.2941\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 0.001187\n",
      "Test Accuracy = 3008 / 10000 = 0.3008\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "accuracy_list = []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    trn_loss = advtrain(model, device, perturbed_train, optimizer, epoch, log_interval, train_loader)\n",
    "    train_losses.append(trn_loss)\n",
    "    accuracy, L2_correct, L2_failed = test(model, device, perturbed_test)\n",
    "    accuracy_list.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './model/mnist_deepfool_model.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pf_images(model, device, perturbed_data):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    failed_image = []\n",
    "    correct_image = []\n",
    "    \n",
    "    for idx, (data, target) in enumerate(perturbed_data):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "        # dim 1에서 가장 큰 값을 가지는 것의 index를 반환\n",
    "        pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "        final_pred = output.max(1, keepdim=True)[1]\n",
    "        # pred.eq(data)는 pred와 data 배열이 일치하는지를 검사\n",
    "        # target을 pred처럼 보이게 만들어서 .sum()을 이용해 일치하는 것들의 개수를 구한다\n",
    "        # .item()은 tensor의 값을 스칼라로 만드는 역할을 한다\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        for j in pred.eq(target.view_as(pred)):\n",
    "            if j == 1:\n",
    "                correct_image.append((data, target.item(), final_pred.item()))\n",
    "            else:\n",
    "                failed_image.append((data, target.item(), final_pred.item()))\n",
    "    return correct_image, failed_image\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "\n",
    "correct, failed = get_pf_images(model, device, perturbed_test)\n",
    "SAVE_PATH = './examples/deepfool/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (image, label, pred) in enumerate(failed):\n",
    "    if idx < 10:\n",
    "        title = SAVE_PATH + 'fail/' + str(idx) +'_'+ str(label) + '_' + str(pred) +'.png'\n",
    "        save_image(image, title)\n",
    "    else: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (image, label, pred) in enumerate(correct):\n",
    "    if idx < 10:\n",
    "        title = SAVE_PATH + 'correct/' + str(idx) +'_'+ str(label) + '_' + str(pred) +'.png'\n",
    "        save_image(image, title)\n",
    "    else: break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
