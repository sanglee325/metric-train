{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.models as models\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from advertorch.attacks import JacobianSaliencyMapAttack as JSMA\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistModel, self).__init__()\n",
    "        # mnist의 경우 28*28의 흑백이미지(input channel=1)이다.\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size = 5, padding=2)\n",
    "        # feature map의 크기는 14*14가 된다\n",
    "        # 첫번재 convolution layer에서 나온 output channel이 32이므로 2번째 input도 32\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size = 5, padding=2)\n",
    "        # feature map의 크기는 7*7이 된다\n",
    "        # fc -> fully connected, fc는 모든 weight를 고려해서 만들기 때문에 cnn에서는 locally connected를 이용하여 만든다.\n",
    "        # nn.Linear에서는 conv를 거친 feature map을 1차원으로 전부 바꿔서 input을 한다. 이게 64*7*7\n",
    "        self.fc1 = nn.Linear(64*7*7, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, 64*7*7) # linear에 들어갈 수 있도록 reshape\n",
    "        x = F.relu(self.fc1(x)) # fully connected에 relu 적용\n",
    "        x = F.dropout(x, training=self.training) # 가중치 감소만으로는 overfit을 해결하기가 어려움, 그래서 뉴런의 연결을 임의로 삭제\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advtrain(model, device, perturbed_data, train_loader, optimizer, epoch, log_interval):\n",
    "    model.train()\n",
    "    avg_loss = 0\n",
    "    # in training loop:\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(perturbed_data):\n",
    "        # gpu나 cpu로 데이터를 옮김\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # gradient descent전에 gradient buffer를 0으로 초기화 하는 역할을 한다\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # negative log-likelihood: nll loss, 딥러닝 모델의 손실함수이다\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step() # Does the update based on the current gradient stored in grad\n",
    "        # 여기서 기존에 저장되어있던 gradient를 기반으로 update 하기 때문에 위의 초기화가 필요함\n",
    "        avg_loss+=F.nll_loss(output, target, reduction='sum').item()\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    avg_loss/=len(train_loader.dataset)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, perturbed_data, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    # .no_grad는 required_grad = True여도 gradient 계산을 하지 않고 더 빠르게 넘어갈 수 있도록 한다\n",
    "    # training이 아니기 때문에 gradient 계산을 할 필요가 없음\n",
    "    for idx, (data, target) in enumerate(perturbed_data):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "        # dim 1에서 가장 큰 값을 가지는 것의 index를 반환\n",
    "        pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "        # pred.eq(data)는 pred와 data 배열이 일치하는지를 검사\n",
    "        # target을 pred처럼 보이게 만들어서 .sum()을 이용해 일치하는 것들의 개수를 구한다\n",
    "        # .item()은 tensor의 값을 스칼라로 만드는 역할을 한다\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        #image = image.numpy()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size=64\n",
    "test_batch_size=1\n",
    "epochs=30\n",
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "seed = 1\n",
    "log_interval = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if is_cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model = './model/mnist_um.pth'\n",
    "model = MnistModel().to(device)\n",
    "model.load_state_dict(torch.load(pretrained_model, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 2 GPUs!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): MnistModel(\n",
       "    (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (fc1): Linear(in_features=3136, out_features=1024, bias=True)\n",
       "    (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "um = MnistModel().to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "    um = nn.DataParallel(um)\n",
    "\n",
    "um.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# momentum: 기울기에서 속도의 개념을 추가, 기울기 업데이트시 폭을 조절한다\n",
    "# lr: learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "# mean=0.5 std=1.0으로 Normalize한다\n",
    "mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_path = './data'\n",
    "train_dataset = MNIST(download_path, transform=mnist_transform, train=True, download=True)\n",
    "test_dataset = MNIST(download_path, transform=mnist_transform, train=False, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=train_batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=test_batch_size,\n",
    "                                          shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsma_attack(um, device, loader):\n",
    "    adversary = JSMA(um, num_classes=10, clip_min=0.0, clip_max=1.0,\n",
    "                    loss_fn=None, theta=1.0, gamma=0.3, comply_cleverhans=False)\n",
    "\n",
    "    perturbed_images = []\n",
    "    for idx, (image, label) in enumerate(loader):\n",
    "        #print(idx)\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        perturbed_image = adversary.perturb(image, label)\n",
    "        perturbed_images.append((perturbed_image, label))\n",
    "        \n",
    "    return perturbed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perturbed_test = jsma_attack(model, device, test_loader)\n",
    "perturbed_test = jsma_attack(um, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perturbed_train = jsma_attack(model, device, train_loader)\n",
    "perturbed_train = jsma_attack(um, device, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 1.774383\n",
      "\n",
      "Test set: Average loss: 0.2032, Accuracy: 9365/10000 (94%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.068776\n",
      "\n",
      "Test set: Average loss: 0.3669, Accuracy: 8958/10000 (90%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.037693\n",
      "\n",
      "Test set: Average loss: 0.4292, Accuracy: 8861/10000 (89%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.004313\n",
      "\n",
      "Test set: Average loss: 0.5768, Accuracy: 8624/10000 (86%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.001254\n",
      "\n",
      "Test set: Average loss: 0.6596, Accuracy: 8473/10000 (85%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.001780\n",
      "\n",
      "Test set: Average loss: 0.6062, Accuracy: 8591/10000 (86%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.002346\n",
      "\n",
      "Test set: Average loss: 0.6748, Accuracy: 8534/10000 (85%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.007514\n",
      "\n",
      "Test set: Average loss: 0.6946, Accuracy: 8501/10000 (85%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.003655\n",
      "\n",
      "Test set: Average loss: 0.7429, Accuracy: 8443/10000 (84%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.007238\n",
      "\n",
      "Test set: Average loss: 0.6887, Accuracy: 8522/10000 (85%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.000526\n",
      "\n",
      "Test set: Average loss: 0.8290, Accuracy: 8360/10000 (84%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.001203\n",
      "\n",
      "Test set: Average loss: 0.7482, Accuracy: 8485/10000 (85%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.000978\n",
      "\n",
      "Test set: Average loss: 0.8226, Accuracy: 8400/10000 (84%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.002527\n",
      "\n",
      "Test set: Average loss: 0.9290, Accuracy: 8343/10000 (83%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.000326\n",
      "\n",
      "Test set: Average loss: 0.9158, Accuracy: 8358/10000 (84%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.005311\n",
      "\n",
      "Test set: Average loss: 0.9767, Accuracy: 8300/10000 (83%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.000290\n",
      "\n",
      "Test set: Average loss: 0.9946, Accuracy: 8322/10000 (83%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.003020\n",
      "\n",
      "Test set: Average loss: 0.9330, Accuracy: 8335/10000 (83%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.000958\n",
      "\n",
      "Test set: Average loss: 0.9611, Accuracy: 8266/10000 (83%)\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.002357\n",
      "\n",
      "Test set: Average loss: 0.9735, Accuracy: 8308/10000 (83%)\n",
      "\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.001444\n",
      "\n",
      "Test set: Average loss: 1.0239, Accuracy: 8229/10000 (82%)\n",
      "\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.003985\n",
      "\n",
      "Test set: Average loss: 0.9730, Accuracy: 8334/10000 (83%)\n",
      "\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.000422\n",
      "\n",
      "Test set: Average loss: 0.9140, Accuracy: 8413/10000 (84%)\n",
      "\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.000231\n",
      "\n",
      "Test set: Average loss: 1.0310, Accuracy: 8285/10000 (83%)\n",
      "\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.007826\n",
      "\n",
      "Test set: Average loss: 1.0253, Accuracy: 8281/10000 (83%)\n",
      "\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.001401\n",
      "\n",
      "Test set: Average loss: 1.1876, Accuracy: 8140/10000 (81%)\n",
      "\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.000472\n",
      "\n",
      "Test set: Average loss: 1.1727, Accuracy: 8136/10000 (81%)\n",
      "\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.000561\n",
      "\n",
      "Test set: Average loss: 1.2854, Accuracy: 8070/10000 (81%)\n",
      "\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.000111\n",
      "\n",
      "Test set: Average loss: 1.1291, Accuracy: 8185/10000 (82%)\n",
      "\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.001787\n",
      "\n",
      "Test set: Average loss: 1.2761, Accuracy: 8081/10000 (81%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "accuracy_list = []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    trn_loss = advtrain(model, device, perturbed_train, train_loader, optimizer, epoch, log_interval)\n",
    "    train_losses.append(trn_loss)\n",
    "    test_loss,accuracy = test(model, device, perturbed_test, test_loader)\n",
    "    test_losses.append(test_loss)\n",
    "    accuracy_list.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './model/mnist_jsma_adver1.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pf_images(model, device, perturbed_data):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    failed_image = []\n",
    "    correct_image = []\n",
    "    \n",
    "    for idx, (data, target) in enumerate(perturbed_data):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "        # dim 1에서 가장 큰 값을 가지는 것의 index를 반환\n",
    "        pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "        final_pred = output.max(1, keepdim=True)[1]\n",
    "        # pred.eq(data)는 pred와 data 배열이 일치하는지를 검사\n",
    "        # target을 pred처럼 보이게 만들어서 .sum()을 이용해 일치하는 것들의 개수를 구한다\n",
    "        # .item()은 tensor의 값을 스칼라로 만드는 역할을 한다\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        for j in pred.eq(target.view_as(pred)):\n",
    "            if j == 1:\n",
    "                correct_image.append((data, target.item(), final_pred.item()))\n",
    "            else:\n",
    "                failed_image.append((data, target.item(), final_pred.item()))\n",
    "    return correct_image, failed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct, failed = get_pf_images(model, device, perturbed_test)\n",
    "SAVE_PATH = './examples/jsma/advertorch_um/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (image, label, pred) in enumerate(failed):\n",
    "    if idx < 10:\n",
    "        title = SAVE_PATH + 'fail/' + str(idx) +'_'+ str(label) + '_' + str(pred) +'.png'\n",
    "        save_image(image, title)\n",
    "    else: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (image, label, pred) in enumerate(correct):\n",
    "    if idx < 10:\n",
    "        title = SAVE_PATH + 'correct/' + str(idx) +'_'+ str(label) + '_' + str(pred) +'.png'\n",
    "        save_image(image, title)\n",
    "    else: break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
