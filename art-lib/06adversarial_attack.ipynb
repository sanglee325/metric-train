{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from art.attacks import FastGradientMethod\n",
    "from art.attacks import DeepFool\n",
    "from art.attacks import SaliencyMapMethod\n",
    "from art.attacks import ProjectedGradientDescent\n",
    "from art.classifiers import PyTorchClassifier\n",
    "from art.utils import load_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistModel, self).__init__()\n",
    "        # mnist의 경우 28*28의 흑백이미지(input channel=1)이다.\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size = 5, padding=2)\n",
    "        # feature map의 크기는 14*14가 된다\n",
    "        # 첫번재 convolution layer에서 나온 output channel이 32이므로 2번째 input도 32\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size = 5, padding=2)\n",
    "        # feature map의 크기는 7*7이 된다\n",
    "        # fc -> fully connected, fc는 모든 weight를 고려해서 만들기 때문에 cnn에서는 locally connected를 이용하여 만든다.\n",
    "        # nn.Linear에서는 conv를 거친 feature map을 1차원으로 전부 바꿔서 input을 한다. 이게 64*7*7\n",
    "        self.fc1 = nn.Linear(64*7*7, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, 64*7*7) # linear에 들어갈 수 있도록 reshape\n",
    "        x = F.relu(self.fc1(x)) # fully connected에 relu 적용\n",
    "        x = F.dropout(x, training=self.training) # 가중치 감소만으로는 overfit을 해결하기가 어려움, 그래서 뉴런의 연결을 임의로 삭제\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test), min_pixel_value, max_pixel_value = load_mnist()\n",
    "\n",
    "x_train = np.swapaxes(x_train, 1, 3).astype(np.float32)\n",
    "x_test = np.swapaxes(x_test, 1, 3).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available!\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if is_cuda else 'cpu')\n",
    "if is_cuda: print(\"CUDA available!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean model loaded\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "model_path = './model/mnist_um_art.pth'\n",
    "model = MnistModel().to(device)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "models.append(model)\n",
    "\n",
    "print(\"clean model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linf trained model1 loaded\n"
     ]
    }
   ],
   "source": [
    "model_path = './model/mnist_fgsm_art.pth'\n",
    "model = MnistModel().to(device)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "models.append(model)\n",
    "\n",
    "print(\"Linf trained model1 loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linf trained model2 loaded\n"
     ]
    }
   ],
   "source": [
    "model_path = './model/mnist_pgd_art.pth'\n",
    "model = MnistModel().to(device)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "models.append(model)\n",
    "\n",
    "print(\"Linf trained model2 loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L0 trained model loaded\n"
     ]
    }
   ],
   "source": [
    "model_path = './model/mnist_jsma_art.pth'\n",
    "model = MnistModel().to(device)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "models.append(model)\n",
    "\n",
    "print(\"L0 trained model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 trained model loaded\n"
     ]
    }
   ],
   "source": [
    "model_path = './model/mnist_deepfool_art.pth'\n",
    "model = MnistModel().to(device)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "models.append(model)\n",
    "\n",
    "print(\"L2 trained model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create the ART classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifiers created\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 0-um, 1-fgsm, 2-fgsm, 3-pgd, 4-jsma, 5-deepfool\n",
    "classifiers = []\n",
    "for model in models:\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "    classifier = PyTorchClassifier(model=model, clip_values=(min_pixel_value, max_pixel_value), loss=criterion,\n",
    "                               optimizer=optimizer, input_shape=(1, 28, 28), nb_classes=10)\n",
    "    classifiers.append(classifier)\n",
    "\n",
    "print(\"classifiers created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate classifier on benign test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model #:\t0-um, 1-fgsm, 2-fgsm, 3-pgd, 4-jsma, 5-deepfool\n",
      "\n",
      "model #0\tAccuracy on benign test examples: 99.26%\n",
      "model #1\tAccuracy on benign test examples: 99.25%\n",
      "model #2\tAccuracy on benign test examples: 99.15%\n",
      "model #3\tAccuracy on benign test examples: 99.27%\n",
      "model #4\tAccuracy on benign test examples: 99.27%\n"
     ]
    }
   ],
   "source": [
    "benign_accuracy = []\n",
    "\n",
    "print('model #:\\t0-um, 1-fgsm, 2-fgsm, 3-pgd, 4-jsma, 5-deepfool\\n')\n",
    "for idx, (classifer) in enumerate(classifiers):\n",
    "    predictions = classifier.predict(x_test)\n",
    "    accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "    print('model #{}\\tAccuracy on benign test examples: {}%'.format(idx, accuracy * 100))\n",
    "    benign_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generate adversarial test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGSM example generated\n"
     ]
    }
   ],
   "source": [
    "adv_attacks = []\n",
    "clean = classifiers[0]\n",
    "\n",
    "Linf1_attack = FastGradientMethod(classifier=clean, eps=0.3)\n",
    "Linf1_x_test_adv = Linf1_attack.generate(x=x_test)\n",
    "adv_attacks.append(Linf1_x_test_adv)\n",
    "\n",
    "print('FGSM example generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGD example generated\n"
     ]
    }
   ],
   "source": [
    "Linf2_attack = ProjectedGradientDescent(classifier=clean, eps=0.3)\n",
    "Linf2_x_test_adv = Linf2_attack.generate(x=x_test)\n",
    "adv_attacks.append(Linf2_x_test_adv)\n",
    "\n",
    "print('PGD example generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSMA example generated\n"
     ]
    }
   ],
   "source": [
    "L0_attack = SaliencyMapMethod(classifier=clean)\n",
    "L0_x_test_adv = L0_attack.generate(x=x_test)\n",
    "adv_attacks.append(L0_x_test_adv)\n",
    "\n",
    "print('JSMA example generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepfool example generated\n"
     ]
    }
   ],
   "source": [
    "L2_attack = DeepFool(classifier=clean)\n",
    "L2_x_test_adv = L2_attack.generate(x=x_test)\n",
    "adv_attacks.append(L2_x_test_adv)\n",
    "\n",
    "print('Deepfool example generated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate each models accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model #:\t0-um, 1-fgsm, 2-fgsm, 3-pgd, 4-jsma, 5-deepfool\n",
      "test #:\t0-fgsm, 1-pgd, 2-jsma, 3-deepfool\n",
      "\n",
      "model #0\n",
      "Accuracy on model with adversarial test #0 examples: 3.02%\n",
      "Accuracy on model with adversarial test #1 examples: 0.74%\n",
      "Accuracy on model with adversarial test #2 examples: 52.959999999999994%\n",
      "Accuracy on model with adversarial test #3 examples: 40.550000000000004%\n",
      "\n",
      "model #1\n",
      "Accuracy on model with adversarial test #0 examples: 98.63%\n",
      "Accuracy on model with adversarial test #1 examples: 85.88%\n",
      "Accuracy on model with adversarial test #2 examples: 48.05%\n",
      "Accuracy on model with adversarial test #3 examples: 79.19%\n",
      "\n",
      "model #2\n",
      "Accuracy on model with adversarial test #0 examples: 86.50999999999999%\n",
      "Accuracy on model with adversarial test #1 examples: 98.59%\n",
      "Accuracy on model with adversarial test #2 examples: 68.92%\n",
      "Accuracy on model with adversarial test #3 examples: 86.66%\n",
      "\n",
      "model #3\n",
      "Accuracy on model with adversarial test #0 examples: 11.31%\n",
      "Accuracy on model with adversarial test #1 examples: 3.1399999999999997%\n",
      "Accuracy on model with adversarial test #2 examples: 71.89%\n",
      "Accuracy on model with adversarial test #3 examples: 67.54%\n",
      "\n",
      "model #4\n",
      "Accuracy on model with adversarial test #0 examples: 84.08%\n",
      "Accuracy on model with adversarial test #1 examples: 62.92%\n",
      "Accuracy on model with adversarial test #2 examples: 79.95%\n",
      "Accuracy on model with adversarial test #3 examples: 98.74000000000001%\n"
     ]
    }
   ],
   "source": [
    "models_accuracy = []\n",
    "\n",
    "print('model #:\\t0-um, 1-fgsm, 2-fgsm, 3-pgd, 4-jsma, 5-deepfool')\n",
    "print('test #:\\t0-fgsm, 1-pgd, 2-jsma, 3-deepfool')\n",
    "\n",
    "# test order: 0-fgsm, 1-pgd, 2-jsma, 3-deepfool\n",
    "for i, (classifier) in enumerate(classifiers):\n",
    "    print('\\nmodel #{}'.format(i))\n",
    "    model_accuracy = []\n",
    "    for j, (x_test_adv) in enumerate(adv_attacks):\n",
    "        predictions = classifier.predict(x_test_adv)\n",
    "        accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "        print('Accuracy on model with adversarial test #{} examples: {}%'.format(j, accuracy * 100))\n",
    "        model_accuracy.append(accuracy)\n",
    "    models_accuracy.append(model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "      <th>Linf1</th>\n",
       "      <th>Linf2</th>\n",
       "      <th>L0</th>\n",
       "      <th>L2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FGSM</th>\n",
       "      <td>0.0302</td>\n",
       "      <td>0.9863</td>\n",
       "      <td>0.8651</td>\n",
       "      <td>0.1131</td>\n",
       "      <td>0.8408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PGD</th>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.8588</td>\n",
       "      <td>0.9859</td>\n",
       "      <td>0.0314</td>\n",
       "      <td>0.6292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JSMA</th>\n",
       "      <td>0.5296</td>\n",
       "      <td>0.4805</td>\n",
       "      <td>0.6892</td>\n",
       "      <td>0.7189</td>\n",
       "      <td>0.7995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deepfool</th>\n",
       "      <td>0.4055</td>\n",
       "      <td>0.7919</td>\n",
       "      <td>0.8666</td>\n",
       "      <td>0.6754</td>\n",
       "      <td>0.9874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           clean   Linf1   Linf2      L0      L2\n",
       "FGSM      0.0302  0.9863  0.8651  0.1131  0.8408\n",
       "PGD       0.0074  0.8588  0.9859  0.0314  0.6292\n",
       "JSMA      0.5296  0.4805  0.6892  0.7189  0.7995\n",
       "Deepfool  0.4055  0.7919  0.8666  0.6754  0.9874"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "data = {\n",
    "    'clean': models_accuracy[0],\n",
    "    'Linf1': models_accuracy[1],\n",
    "    'Linf2': models_accuracy[2],\n",
    "    'L0': models_accuracy[3],\n",
    "    'L2': models_accuracy[4],\n",
    "}\n",
    "\n",
    "columns = ['clean', 'Linf1', 'Linf2', 'L0', 'L2']\n",
    "idx = ['FGSM', 'PGD', 'JSMA', 'Deepfool']\n",
    "DataFrame(data, columns=columns, index=idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
